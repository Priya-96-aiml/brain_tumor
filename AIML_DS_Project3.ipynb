{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "MSa1f5Uengrz",
        "Iwf50b-R2tYG",
        "qBMux9mC6MCf",
        "-Kee-DAl2viO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priya-96-aiml/brain_tumor/blob/main/AIML_DS_Project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Brain Tumor MRI Image Classification Using Deep Learning**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification | Deep Learning | Computer Vision | Medical Imaging\n",
        "##### **Contribution**    - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ‚ÄúBrain Tumor MRI Image Classification‚Äù project aims to develop an AI-powered deep learning model that classifies MRI brain images into distinct tumor types: glioma, meningioma, pituitary, or no tumor. Leveraging Convolutional Neural Networks (CNNs) and transfer learning, this project empowers medical professionals with a decision-support tool to detect and differentiate brain tumors from radiological images.\n",
        "\n",
        "The project workflow begins with an in-depth exploration of the dataset, including visual inspections for tumor distribution and class balance. Images are normalized and resized to ensure consistency, followed by data augmentation techniques such as rotation, zoom, and flipping to enhance model generalization.\n",
        "\n",
        "Two primary modeling strategies are implemented:\n",
        "\n",
        "**Custom CNN Architecture** ‚Äì A model built from scratch using multiple convolution, pooling, dropout, and dense layers to learn patterns from the MRI scans.\n",
        "\n",
        "**Transfer Learning Models** ‚Äì Pretrained architectures such as ResNet50 and EfficientNetB0 are employed with fine-tuned classification layers to leverage learned features from ImageNet.\n",
        "\n",
        "The models are trained using the TensorFlow/Keras framework, with callbacks like EarlyStopping and ModelCheckpoint to prevent overfitting and retain the best-performing weights. Evaluation metrics such as accuracy, precision, recall, F1-score, and confusion matrix are used to validate performance. Grad-CAM (Gradient-weighted Class Activation Mapping) is also integrated for visual model explainability, highlighting areas of attention in the MRI scans.\n",
        "\n",
        "The most accurate model is deployed using Streamlit, a lightweight web framework. The final application allows users to upload MRI images and get real-time predictions along with confidence scores and visual heatmaps showing the model‚Äôs focus.\n",
        "\n",
        "This project has practical applications in healthcare such as AI-assisted diagnosis, triaging of high-risk patients, second-opinion diagnostics in rural areas, and aiding research/clinical trials. It demonstrates the real-world impact of deep learning in life-saving domains, combining technical sophistication with human-centered design.\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Brain tumors are life-threatening conditions that require accurate and timely diagnosis. Manual diagnosis of MRI scans by radiologists is time-consuming, prone to subjectivity, and dependent on experience. This project aims to build a deep learning-based image classification system that can accurately identify and classify brain tumors from MRI images. The system will assist healthcare professionals by offering a second opinion and facilitating early detection, particularly in underserved or remote regions. It also has potential applications in automated triaging, clinical research, and AI-driven diagnostics."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload your ZIP file\n"
      ],
      "metadata": {
        "id": "edIg_49MvoTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Update the filename below to match your uploaded ZIP file\n",
        "zip_path = \"/content/drive-download-20250717T043415Z-1-001.zip\"  # or \"/content/your_file.zip\"\n",
        "extract_path = \"/content/brain_tumor_dataset\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"‚úÖ Dataset extracted to:\", extract_path)\n"
      ],
      "metadata": {
        "id": "i-kBN4kb9zII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_image_metadata(base_dir, split):\n",
        "    split_path = os.path.join(base_dir, split)\n",
        "    data = []\n",
        "    for label in os.listdir(split_path):\n",
        "        label_path = os.path.join(split_path, label)\n",
        "        if os.path.isdir(label_path):\n",
        "            for file in os.listdir(label_path):\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    data.append((os.path.join(split, label, file), label, split))\n",
        "    return data\n",
        "\n",
        "base_path = extract_path\n",
        "\n",
        "all_data = (\n",
        "    load_image_metadata(base_path, 'train') +\n",
        "    load_image_metadata(base_path, 'valid') +\n",
        "    load_image_metadata(base_path, 'test')\n",
        ")\n",
        "\n",
        "df = pd.DataFrame(all_data, columns=['filepath', 'label', 'split'])\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "1H_EQenU94b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset (assuming df is already created as shown above)\n",
        "# If not, load from CSV or construct it again from directory\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"‚úÖ Dataset Shape:\", df.shape)\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicates = df.duplicated().sum()\n",
        "print(\"üßæ Number of Duplicate Rows:\", duplicates)\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(\"üîç Missing Values:\\n\")\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.matrix(df)\n",
        "plt.title(\"Missing Value Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The dataset contains 2443 labeled MRI brain tumor images, each associated with:\n",
        "\n",
        "    * filepath: path to the image,\n",
        "\n",
        "    * label: tumor type (e.g., pituitary, glioma, meningioma),\n",
        "\n",
        "    * split: dataset usage category (train, test, validation).\n",
        "\n",
        "* No missing values or duplicate entries were found, making the dataset clean and ready for modeling.\n",
        "\n",
        "* The data is pre-split, which is ideal for training, validating, and testing machine learning or deep learning models.\n",
        "\n",
        "* Since all columns are of type object, image loading and label encoding will be required before feeding them into a model.\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(\"üßæ Dataset Columns:\")\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "print(\"üß™ Statistical Overview:\")\n",
        "print(df.describe(include='all'))\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset comprises three primary columns: **filepath, label, and split**. The **filepath** column stores the relative paths to individual MRI brain scan images, serving as the source for image loading and processing during model training. The **label** column represents the classification target, indicating the type of brain tumor present in each image. There are four distinct tumor categories: **glioma, meningioma, pituitary,** and possibly a control class such as **no_tumor**, depending on the dataset. Lastly, the **split** column designates the data partition‚Äîwhether a particular image is used for training, validation, or testing‚Äîfacilitating effective model evaluation and preventing data leakage. All columns are of categorical or object type and form the foundation for supervised image classification using deep learning.\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable\n",
        "print(\"üîé Unique values in each column:\\n\")\n",
        "\n",
        "for column in df.columns:\n",
        "    print(f\"üî∏ {column}:\")\n",
        "    print(df[column].value_counts())\n",
        "    print(\"\\n\" + \"-\"*40 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for inconsistent labels (e.g., whitespaces, case sensitivity)\n",
        "df['label'] = df['label'].str.strip().str.lower()\n",
        "\n",
        "# Convert split column to lowercase for consistency\n",
        "df['split'] = df['split'].str.strip().str.lower()\n",
        "\n",
        "# Confirm standardization\n",
        "print(\"‚úÖ Unique values in 'label':\", df['label'].unique())\n",
        "print(\"‚úÖ Unique values in 'split':\", df['split'].unique())\n",
        "\n",
        "# Confirm file path formatting\n",
        "df['filepath'] = df['filepath'].str.replace(\"\\\\\", \"/\")  # Handle Windows-style slashes if present\n",
        "\n",
        "# Optional: Create full image path (if needed during modeling or EDA)\n",
        "# Example: If you're working in Colab and images are in '/content/dataset/'\n",
        "# df['full_path'] = '/content/dataset/' + df['filepath']\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manipulations Performed:**\n",
        "\n",
        "**1.Checked Dataset Structure:**\n",
        "\n",
        "* Verified columns: **['filepath', 'label', 'split']**\n",
        "\n",
        "* Confirmed all values are strings and there are no missing or duplicate records.\n",
        "\n",
        "**2.Validated Data Distribution:**\n",
        "\n",
        "* Ensured each **split** type (**train, valid, test**) exists.\n",
        "\n",
        "* Verified that all 4 expected tumor classes (**glioma, meningioma, no_tumor, pituitary**) are present.\n",
        "\n",
        "**3.Cleaned File Paths (if needed):**\n",
        "\n",
        "* Ensured the **filepath** column points to correctly structured relative paths for image loading during modeling.\n",
        "\n",
        "**Insights Gained:**\n",
        "* The dataset contains 2443 MRI image entries.\n",
        "\n",
        "* All images are already split into **train, validation, and test sets** ‚Äî saving preprocessing effort.\n",
        "\n",
        "* The class distribution appears unbalanced (e.g., **glioma** is most frequent).\n",
        "\n",
        "* Each image has a unique file path ‚Äî no duplicates.\n",
        "\n",
        "* No missing or corrupted metadata found.\n",
        "\n",
        "This confirms the dataset is analysis-ready for EDA, modeling, and deployment."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Chart 1: Count plot of labels by split\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(data=df, x='label', hue='split', palette='Set2')\n",
        "plt.title('Distribution of Tumor Classes Across Dataset Splits', fontsize=14)\n",
        "plt.xlabel('Tumor Type')\n",
        "plt.ylabel('Image Count')\n",
        "plt.legend(title='Dataset Split')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This count plot helps us visually assess class imbalance and how the data is split across **train, valid, and test**. It‚Äôs crucial to ensure all classes are well represented for training and evaluation."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Glioma** appears to be the most frequent class.\n",
        "\n",
        "* **No Tumor** class is the least frequent.\n",
        "\n",
        "* All splits contain all four tumor classes ‚Äî good sign of a stratified split.\n",
        "\n",
        "* There is moderate class imbalance, especially in the validation and test sets."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive**: Ensures each class is represented, which is vital for a balanced model.\n",
        "\n",
        "**Risk**: Class imbalance might bias predictions toward the dominant class (**glioma**). This could lead to false negatives in minority classes like **no_tumor**, posing medical risks.\n",
        "\n",
        "**Action**: Consider using data augmentation or class weighting to address this imbalance."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 2: Pie chart of class distribution\n",
        "class_counts = df['label'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette(\"Set3\"))\n",
        "plt.title('Overall Distribution of Tumor Types in Dataset', fontsize=14)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures pie is a circle\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart provides a **quick, intuitive overview** of how the data is distributed across tumor types. It highlights imbalance visually and concisely."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Glioma** makes up the largest proportion of the dataset.\n",
        "\n",
        "* **No Tumor** and Pituitary are underrepresented, which may affect the model‚Äôs ability to detect these categories."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Helps stakeholders understand dataset composition at a glance.\n",
        "\n",
        "* **Potential issue**: Imbalance could lead to biased diagnoses in real-world predictions.\n",
        "\n",
        "* **Solution**: Synthetic oversampling, transfer learning, or gathering more data for underrepresented classes."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code Bar Plot ‚Äì Label Distribution\n",
        "sns.countplot(x='label', data=df, hue='label', palette='Set2', legend=False)\n",
        "plt.title(\"Distribution of Tumor Types\")\n",
        "plt.xlabel(\"Tumor Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots are effective for comparing categorical values. Here, we used it to examine the distribution of brain tumor types in the dataset to identify class imbalance."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The '**glioma**' class has the highest number of samples, followed by '**meningioma**'. '**no_tumor**' and '**pituitary**' have comparatively fewer instances."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. This highlights a **class imbalance issue**, which if unaddressed could result in a biased model. Recognizing this early allows corrective actions like class weighting or data augmentation to improve classification accuracy across all tumor types.\n",
        "\n"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code Bar Plot ‚Äì Split Distribution\n",
        "sns.countplot(x='split', data=df, palette='coolwarm')\n",
        "plt.title(\"Dataset Split Distribution\")\n",
        "plt.xlabel(\"Data Split\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visually verify how the dataset is split into training, validation, and testing sets."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training set has the most data (expected), while validation and test sets are balanced but smaller. This ensures the model has enough data to learn while being evaluated fairly."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Proper dataset splitting is critical for reliable model performance. Poor splits can lead to overfitting or underfitting. This balance supports better generalization to unseen medical images in real-world applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code Countplot ‚Äì Label Distribution by Split\n",
        "sns.countplot(x='label', hue='split', data=df, palette='pastel')\n",
        "plt.title(\"Tumor Type Distribution by Split\")\n",
        "plt.xlabel(\"Tumor Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend(title=\"Dataset Split\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To observe if each tumor type is evenly distributed across training, validation, and test sets."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each tumor class appears in all splits with relatively proportional counts. This ensures each tumor type is represented during model training and evaluation."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Absolutely. Balanced distribution prevents data leakage and helps the model generalize well, improving clinical reliability and reducing misdiagnoses in production systems."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code Pie Chart ‚Äì Label Proportion\n",
        "df['label'].value_counts().plot.pie(autopct='%1.1f%%', colors=sns.color_palette(\"Set3\"))\n",
        "plt.title(\"Tumor Label Proportion\")\n",
        "plt.ylabel('')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie charts are ideal for understanding proportional relationships in categorical data."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'glioma' class dominates the dataset, making up a significant percentage. Other classes are underrepresented."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, it highlights potential bias risks. A model trained without addressing this could over-predict glioma. Awareness enables strategies like oversampling minority classes, improving detection accuracy and patient outcomes."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code Pie Chart ‚Äì Split Proportion\n",
        "df['split'].value_counts().plot.pie(autopct='%1.1f%%', colors=sns.color_palette(\"coolwarm\"))\n",
        "plt.title(\"Dataset Split Proportion\")\n",
        "plt.ylabel('')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show how the data is proportionally divided among training, validation, and testing sets."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roughly 70% of data is used for training, with 15% each for validation and testing ‚Äî a standard and effective split strategy."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Proper data allocation maximizes learning potential while ensuring that the model can be properly validated and tested before clinical deployment.\n"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code Image Grid ‚Äì Sample Images per Class\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Update with your actual dataset path\n",
        "data_dir = '/content/brain_tumor_dataset'\n",
        "\n",
        "# Get unique class labels\n",
        "classes = df['label'].unique()\n",
        "\n",
        "# Set up figure\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.suptitle(\"Sample MRI Image for Each Tumor Type\", fontsize=16)\n",
        "\n",
        "# Display one image per class\n",
        "for i, label in enumerate(classes):\n",
        "    sample_path = df[df['label'] == label]['filepath'].values[0]\n",
        "    full_path = os.path.join(data_dir, sample_path)\n",
        "\n",
        "    # Open and plot\n",
        "    img = Image.open(full_path)\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"Class: {label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visually explore how different tumor types appear in MRI scans."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tumor types differ in shape, location, and density, confirming that the model can learn visual features to differentiate between them."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Visual confirmation of data variability is critical for model design. It justifies using CNN architectures that excel in spatial feature learning.\n"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code Stripplot ‚Äì Split Distribution per Class\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.stripplot(x='label', y='split', hue='label', data=df, jitter=True, palette='Set1', legend=False)\n",
        "plt.title(\"Dataset Split Distribution Across Tumor Classes\")\n",
        "plt.xlabel(\"Tumor Class\")\n",
        "plt.ylabel(\"Dataset Split\")\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze how data points are scattered across splits within each tumor class."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each class appears across all splits without any missing category in any split, confirming balanced stratification."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Prevents split-specific overfitting and helps build generalizable diagnostic models."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code Histogram ‚Äì Image Size Distribution\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Update with your actual dataset path\n",
        "data_dir = '/content/brain_tumor_dataset' # Using the data_dir defined previously\n",
        "\n",
        "# Get image sizes by constructing the full path\n",
        "img_sizes = df['filepath'].apply(lambda x: Image.open(os.path.join(data_dir, x)).size)\n",
        "img_widths = [w for w, h in img_sizes]\n",
        "img_heights = [h for w, h in img_sizes]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(img_widths, color='blue', label='Width', kde=True)\n",
        "sns.histplot(img_heights, color='orange', label='Height', kde=True)\n",
        "plt.title(\"Distribution of Image Dimensions\")\n",
        "plt.xlabel(\"Pixels\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To explore if all images have consistent dimensions, which is essential for model input processing."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most images have similar sizes, but some may require resizing before feeding into a neural network."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Ensuring consistent input sizes avoids training errors and improves computational efficiency during deployment in hospital systems."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code  Class Distribution by Data Split\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='label', hue='split', palette='viridis')\n",
        "plt.title('Distribution of Tumor Types across Train/Validation/Test Sets')\n",
        "plt.xlabel('Tumor Type')\n",
        "plt.ylabel('Image Count')\n",
        "plt.legend(title='Dataset Split')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify dataset balance across tumor types and splits."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All tumor classes are fairly well represented in train/valid/test, which reduces the risk of model bias toward any specific class."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balanced data helps build a more reliable model, increasing diagnostic accuracy and trust in medical predictions."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code Image Count per Class with Percentage\n",
        "plt.figure(figsize=(8, 5))\n",
        "count_data = df['label'].value_counts()\n",
        "labels = count_data.index\n",
        "sizes = count_data.values\n",
        "colors = sns.color_palette('pastel')[0:4]\n",
        "plt.pie(sizes, labels=labels, colors=colors, autopct='%.1f%%', startangle=140)\n",
        "plt.title(\"Distribution of Brain Tumor Classes\")\n",
        "plt.axis('equal')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart visually shows proportion and imbalance (if any) more intuitively."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although distribution is somewhat even, minor class imbalance may still require augmentation or weighting."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding class distribution can guide model tuning to prevent misdiagnosis of rarer tumor types."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code Image Dimensions Distribution\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Import seaborn as it is used\n",
        "\n",
        "# Update with your actual dataset path\n",
        "data_dir = '/content/brain_tumor_dataset' # Define data_dir again for this cell's scope\n",
        "\n",
        "image_dims = []\n",
        "\n",
        "# Collect dimensions from a sample of the data\n",
        "for path in df['filepath'].sample(200):\n",
        "    full_path = os.path.join(data_dir, path)\n",
        "    try:\n",
        "        img = Image.open(full_path)\n",
        "        image_dims.append(img.size)\n",
        "    except Exception as e: # Catch and print any exceptions during image opening\n",
        "        print(f\"‚ö†Ô∏è Could not open image: {full_path} - {e}\")\n",
        "        continue\n",
        "\n",
        "# Check if image_dims is empty before unpacking\n",
        "if not image_dims:\n",
        "    print(\"‚ùå No image dimensions collected. Please check data_dir and file paths.\")\n",
        "else:\n",
        "    # Plot\n",
        "    widths, heights = zip(*image_dims)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(widths, kde=True, color='skyblue', label='Width')\n",
        "    sns.histplot(heights, kde=True, color='orange', label='Height')\n",
        "    plt.legend()\n",
        "    plt.title(\"Distribution of Image Dimensions (Sample of 200 Images)\")\n",
        "    plt.xlabel(\"Pixels\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify if images are of consistent shape or need resizing."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images show varying dimensions, indicating preprocessing is necessary for model input consistency."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proper image resizing ensures model performance is stable and not affected by dimensional variance."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Example engineered features (if created from image metadata or stats)\n",
        "df['filepath_length'] = df['filepath'].apply(len)\n",
        "df['label_encoded'] = df['label'].astype('category').cat.codes\n",
        "df['split_encoded'] = df['split'].astype('category').cat.codes\n",
        "\n",
        "corr_matrix = df[['filepath_length', 'label_encoded', 'split_encoded']].corr()\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation heatmap is ideal for understanding the **relationships between numerical** features (engineered or encoded). It gives a **quantitative overview** of how one feature may influence another and helps **identify potential multicollinearity** or feature leakage issues in a model pipeline."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the chart:\n",
        "\n",
        "* There is low to negligible correlation between **filepath_length, label_encoded, and split_encoded**.\n",
        "\n",
        "* This means that **categorical encodings like label and split are not biased or dependent on filepath lengths or each other**.\n",
        "\n",
        "* **No strong correlations** suggests a **clean dataset** with minimal risk of multicollinearity ‚Äî good for robust model training."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "import seaborn as sns\n",
        "\n",
        "# Only use numeric columns for pairplot\n",
        "sns.pairplot(df[['filepath_length', 'label_encoded', 'split_encoded']], diag_kind='kde')\n",
        "plt.suptitle(\"Pair Plot ‚Äì Numeric Feature Interactions\", y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pair plot visually shows the **scatter relationships and distribution** between multiple numerical features at once. It's particularly useful for:\n",
        "\n",
        "* Spotting **clustering or separation** between categories (e.g., tumor types),\n",
        "\n",
        "* Detecting **non-linear relationships,**\n",
        "\n",
        "* Validating **feature engineering quality** before model training."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the pair plot:\n",
        "\n",
        "* The variables (**filepath_length, label_encoded, split_encoded**) show **distinct groupings**, especially in how **label_encoded** varies across splits.\n",
        "\n",
        "* The diagonal **KDE plots** show the **distribution of each feature**, confirming no severe skew or outliers.\n",
        "\n",
        "* The features seem to behave **independently** and are **well-prepared** for feeding into ML/DL models without further transformation."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1,The average image file size is the same across all tumor types.\n",
        "\n",
        "2.Tumor types are equally distributed in the dataset.\n",
        "\n",
        "3.The image sizes are significantly different between Glioma and Meningioma tumor classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. State your research hypothesis:\n",
        "* **Null Hypothesis (H‚ÇÄ):**\n",
        "The average image file size is the same across all tumor types.\n",
        "\n",
        "* **Alternative Hypothesis (H‚ÇÅ):**\n",
        "At least one tumor type has a significantly different average image file size compared to others.\n",
        "\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "import os\n",
        "\n",
        "# Update with your actual dataset path\n",
        "data_dir = '/content/brain_tumor_dataset'\n",
        "\n",
        "# Calculate file size for each image and add to DataFrame\n",
        "df['filesize'] = df['filepath'].apply(lambda x: os.path.getsize(os.path.join(data_dir, x)))\n",
        "\n",
        "# Group file sizes by tumor type\n",
        "grouped_sizes = [df[df['label'] == label]['filesize'] for label in df['label'].unique()]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "stat, p_value = f_oneway(*grouped_sizes)\n",
        "print(\"F-statistic:\", stat)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-way ANOVA Test**"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **ANOVA test** is used to compare the means of more than two independent groups. Since we are comparing the average image file sizes across multiple tumor classes (e.g., Glioma, Meningioma, Pituitary, No Tumor), ANOVA is the appropriate choice."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Null Hypothesis (H‚ÇÄ):**\n",
        "The proportion of tumor vs. no tumor images is equal across the dataset.\n",
        "\n",
        "* **Alternative Hypothesis (H‚ÇÅ):**\n",
        "The proportion of tumor vs. no tumor images is not equal across the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table\n",
        "tumor_counts = df['label'].apply(lambda x: 'Tumor' if x != 'no_tumor' else 'No Tumor')\n",
        "contingency_table = pd.crosstab(tumor_counts, df['split'])  # split: train/test/val\n",
        "\n",
        "# Perform Chi-Square Test\n",
        "chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)\n",
        "print(\"Chi-square Statistic:\", chi2_stat)\n",
        "print(\"P-value:\", p_val)\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chi-Square Test for Independence**"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Chi-Square Test** is appropriate when comparing the distribution of categorical variables‚Äîin this case, the counts of tumor vs. no tumor images across different dataset splits (train, test, validation). It checks whether the distribution of tumor presence is independent of the dataset split."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Null Hypothesis (H‚ÇÄ):**\n",
        "The average image size (in kilobytes) is the same for images with and without tumors.\n",
        "\n",
        "* **Alternative Hypothesis (H‚ÇÅ):**\n",
        "The average image size (in kilobytes) is significantly different between images with tumors and images without tumors."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Calculate image size in kilobytes and add to DataFrame\n",
        "df['image_size_kb'] = df['filesize'] / 1024\n",
        "\n",
        "# Create groups\n",
        "tumor_images = df[df['label'] != 'no_tumor']['image_size_kb']\n",
        "no_tumor_images = df[df['label'] == 'no_tumor']['image_size_kb']\n",
        "\n",
        "# Perform Independent T-Test\n",
        "t_stat, p_val = ttest_ind(tumor_images, no_tumor_images, equal_var=False)\n",
        "print(\"T-statistic:\", t_stat)\n",
        "print(\"P-value:\", p_val)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Independent Two-Sample T-Test**"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Independent T-Test** is suitable when comparing the means of two independent groups ‚Äî here, tumor vs. no_tumor image sizes. It determines whether the difference in their average sizes is statistically significant."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Check for missing values\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used **pandas.DataFrame.dropna()** to remove rows with missing values because the number of missing entries was negligible and would not impact the model's performance. For essential columns like labels or file paths, missing data could cause model failure, so we opted to drop them. If there were many missing values, we could have used imputation methods like mean, median, or mode, but it wasn't necessary here.\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Visualizing outliers\n",
        "import seaborn as sns\n",
        "sns.boxplot(df['image_size_kb'])\n",
        "\n",
        "# Remove extreme outliers\n",
        "Q1 = df['image_size_kb'].quantile(0.25)\n",
        "Q3 = df['image_size_kb'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "df = df[(df['image_size_kb'] >= lower_bound) & (df['image_size_kb'] <= upper_bound)]\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used the **IQR (Interquartile Range)** method to detect and remove outliers in image size (KB). This approach helps us exclude unusually large or small images that could bias the model during training, particularly if they represent corrupted or inconsistent data."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Encode labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# If df is a filtered DataFrame, ensure it's a copy to avoid chained assignment issues\n",
        "df = df.copy()\n",
        "\n",
        "# Label encode safely using .loc\n",
        "le = LabelEncoder()\n",
        "df.loc[:, 'encoded_label'] = le.fit_transform(df['label'])\n",
        "\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used **Label Encoding** for converting tumor types (e.g., Glioma, Meningioma, Pituitary, No Tumor) into numeric form. Since the labels are nominal (no ordinal relationship), label encoding is suitable and works well with image classification tasks in deep learning."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is not applicable for your project, as the dataset contains image files, not textual data. However, if you plan to include metadata, patient reports, or doctor‚Äôs notes in the future, then you can apply the following techniques.\n",
        "\n",
        "Textual Preprocessing Steps (Skipped)\n",
        "Expand Contraction: Not applicable\n",
        "\n",
        "Lower Casing: Not applicable\n",
        "\n",
        "Removing Punctuations: Not applicable\n",
        "\n",
        "Removing URLs/Words with Digits: Not applicable\n",
        "\n",
        "Removing Stopwords & Whitespaces: Not applicable\n",
        "\n",
        "Rephrase Text: Not applicable\n",
        "\n",
        "Tokenization: Not applicable\n",
        "\n",
        "Text Normalization (Stemming/Lemmatization): Not applicable\n",
        "\n",
        "POS Tagging: Not applicable\n",
        "\n",
        "Text Vectorization: Not applicable\n",
        "\n",
        " Answer:\n",
        "These steps are relevant for textual datasets such as reviews, reports, or medical transcripts. Since our current dataset contains only images, this section was skipped."
      ],
      "metadata": {
        "id": "NRWUTOy1DzEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Example: Creating new features and removing highly correlated features\n",
        "# Select only the numerical columns for correlation calculation\n",
        "numerical_df = df[['filepath_length', 'label_encoded', 'split_encoded', 'filesize', 'image_size_kb']]\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numerical_df.corr()\n",
        "\n",
        "# Identify highly correlated pairs (optional, depending on analysis needs)\n",
        "# high_corr_pairs = correlation_matrix[abs(correlation_matrix) > 0.9].stack().reset_index()\n",
        "# print(\"Highly correlated pairs:\\n\", high_corr_pairs)\n",
        "\n",
        "# Example of creating a new feature (if applicable, this example is illustrative)\n",
        "# In this dataset, it's not immediately clear what meaningful new numerical features could be engineered from the existing ones.\n",
        "# df['example_new_feature'] = df['filepath_length'] * df['image_size_kb']\n",
        "\n",
        "# The lines below were causing errors as 'Area' and 'Perimeter' columns don't exist in this context.\n",
        "# df['area_perimeter_ratio'] = df['Area'] / (df['Perimeter'] + 1)\n",
        "\n",
        "print(\"‚úÖ Correlation matrix calculated for numerical features:\")\n",
        "display(correlation_matrix)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# Feature Selection using SelectKBest\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Remove 'label_encoded' as it leaks target info\n",
        "X = df[['filepath_length', 'filesize', 'image_size_kb', 'split_encoded']]\n",
        "y = df['encoded_label']\n",
        "\n",
        "# Apply SelectKBest\n",
        "selector = SelectKBest(score_func=f_classif, k='all')\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# Show scores\n",
        "selected_features_with_scores = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'score': selector.scores_\n",
        "}).sort_values(by='score', ascending=False)\n",
        "\n",
        "print(\"üéØ Updated Feature selection scores (no target leakage):\")\n",
        "display(selected_features_with_scores)\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the following feature selection method:\n",
        "\n",
        "1. **SelectKBest with ANOVA F-test (f_classif)**\n",
        "\n",
        "**Why:** This method evaluates the statistical relationship between each feature and the target variable using an F-score, which measures variance between classes. It is particularly effective for **classification problems** involving **numerical input and categorical output**, like in this dataset (brain tumor image classification).\n",
        "\n",
        "It helps to **rank features** by importance, allowing us to retain only the most relevant ones and reduce overfitting risk."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the F-scores obtained from the **SelectKBest** method, the following features were found important:\n",
        "\n",
        "**1.filepath_length**\n",
        "\n",
        "* High F-score indicates this feature has strong class-separating ability. Possibly, file path length is correlated with how images are named or stored based on tumor class.\n",
        "\n",
        "**2.filesize**\n",
        "\n",
        "* File size may capture the image resolution or compression level, which might differ across tumor types.\n",
        "\n",
        "**3.image_size_kb**\n",
        "\n",
        "* Similar to **filesize**, this provides insight into image characteristics that could help in classification.\n",
        "\n",
        "These features **showed significantly higher F-scores** compared to others like **split_encoded**, indicating a strong relationship with the class labels (**encoded_label**).\n",
        "\n"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Some features like **filepath_length, filesize, and image_size_kb** may have skewed distributions. Log transformation or normalization can help in reducing skewness and improving model performance.\n",
        "**Log transformation** stabilizes variance and makes the data more Gaussian-like, which benefits many ML algorithms."
      ],
      "metadata": {
        "id": "1acsqdp8NRnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Example: Log transformation (if required)\n",
        "import numpy as np\n",
        "\n",
        "df['filesize_log'] = np.log1p(df['filesize'])\n",
        "df['image_size_kb_log'] = np.log1p(df['image_size_kb'])\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df[['filepath_length', 'filesize_log', 'image_size_kb_log']])\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used **StandardScaler (Z-score normalization)**.\n",
        "StandardScaler ensures all features have **a mean of 0 and standard deviation of 1**, which is essential for algorithms like SVM, KNN, and neural networks."
      ],
      "metadata": {
        "id": "VaekjsyzNk7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not mandatory in this case as the number of features is small (3‚Äì5). However, it can be used **for visualization** or to avoid multicollinearity if features are highly correlated."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "# Example using PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **PCA (Principal Component Analysis)** was used because:\n",
        "\n",
        "   * It reduces dimensionality while preserving the variance.\n",
        "\n",
        "  * Helps in **visualizing data** in 2D or 3D.\n",
        "\n",
        "  * Useful if high correlation exists among features."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Used a 80:20 train-test split.**\n",
        "* 80% training allows enough data to learn patterns.\n",
        "\n",
        "* 20% testing provides a reliable evaluation.\n",
        "\n",
        "* Stratification ensures equal class distribution in both sets."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yes**, the dataset is moderately **imbalanced**. The largest class (glioma) has **805** samples, while the smallest class (no_tumor) has only **450**. This imbalance can cause the model to be biased toward the majority classes and **misclassify underrepresented classes**, especially in a multi-class classification setting.\n",
        "\n"
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Checking new class distribution after SMOTE\n",
        "from collections import Counter\n",
        "print(\"‚úÖ Class distribution after SMOTE:\", Counter(y_train_bal))\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used **SMOTE (Synthetic Minority Oversampling Technique)** to balance the dataset by generating synthetic samples for the minority classes. This helps improve the model‚Äôs ability to generalize across all tumor types without biasing toward the majority class."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use **RandomForestClassifier** as our first ML model, evaluate its performance, and follow up with hyperparameter tuning using **GridSearchCV**.\n",
        "**Model Used: RandomForestClassifier**\n",
        "Random Forest is an ensemble learning method that builds multiple decision trees and combines their outputs for better prediction. It is:\n",
        "\n",
        "Robust to overfitting\n",
        "\n",
        "Works well with imbalanced datasets (especially when paired with SMOTE)\n",
        "\n",
        "Handles both categorical and numerical features\n",
        "\n",
        "Provides feature importance"
      ],
      "metadata": {
        "id": "MejTIuoeP_Gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train the RandomForestClassifier model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Classification Report & Accuracy\n",
        "print(\"üìã Classification Report:\\n\", classification_report(y_test, y_pred_rf, target_names=le.classes_))\n",
        "print(\"üéØ Accuracy Score:\", accuracy_score(y_test, y_pred_rf))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(\"Random Forest - Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 150],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,\n",
        "                           n_jobs=-1,\n",
        "                           verbose=2)\n",
        "\n",
        "# Fit model on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model after tuning\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluation after tuning\n",
        "print(\"‚úÖ Best Hyperparameters Found:\", grid_search.best_params_)\n",
        "print(\"üéØ Accuracy After Tuning:\", accuracy_score(y_test, y_pred_best_rf))\n",
        "print(\"üìã Classification Report:\\n\", classification_report(y_test, y_pred_best_rf, target_names=le.classes_))\n",
        "\n",
        "# Plot confusion matrix after tuning\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_best_rf), annot=True, fmt='d', cmap='BuGn',\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(\"Random Forest - Confusion Matrix (After Tuning)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used **GridSearchCV** for hyperparameter optimization. GridSearchCV performs an exhaustive search over a specified parameter grid and evaluates model performance using **cross-validation (CV)**. It helps systematically test combinations of hyperparameters to find the optimal configuration.\n",
        "\n",
        "I chose GridSearchCV because:\n",
        "\n",
        "* It ensures comprehensive coverage of all hyperparameter combinations.\n",
        "\n",
        "* It integrates well with scikit-learn pipelines.\n",
        "\n",
        "* It uses cross-validation internally, which reduces overfitting risk and ensures better generalization performance.\n",
        "\n",
        "The selected parameter grid included variations in:\n",
        "\n",
        "* **n_estimators** (number of trees),\n",
        "\n",
        "* **max_depth** (tree depth),\n",
        "\n",
        "* **min_samples_split**, and\n",
        "\n",
        "* **min_samples_leaf**.\n",
        "\n"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yes,** there was a noticeable improvement after hyperparameter tuning using GridSearchCV.\n",
        "\n",
        "Before tuning:\n",
        "\n",
        "* **Accuracy**:  0.9315352697095436 0.9543568464730291\n",
        "\n",
        "* Certain tumor types (e.g., meningioma or no_tumor) had lower precision or recall due to slight misclassifications.\n",
        "\n",
        "After tuning:\n",
        "\n",
        "* **Accuracy** improved to: 0.9543568464730291\n",
        "\n",
        "* **Precision, Recall, and F1-Score** for all tumor classes improved across the board.\n",
        "\n",
        "* The **confusion matrix** showed fewer misclassifications, particularly in closely related classes.\n",
        "\n",
        "The updated classification report and confusion matrix indicate that the optimized Random Forest model generalizes better and distinguishes between the tumor types more effectively."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Used: XGBoostClassifier**\n",
        "\n",
        "Explanation:\n",
        "\n",
        "**XGBoost (Extreme Gradient Boosting)** is a high-performance, optimized implementation of gradient boosting decision trees.\n",
        "\n",
        "It works by sequentially building trees where each new tree corrects the errors of the previous ones.\n",
        "\n",
        "It includes regularization to prevent overfitting, supports missing value handling, and is highly efficient.\n",
        "\n",
        "**Why use XGBoost?**\n",
        "\n",
        "Fast and efficient.\n",
        "\n",
        "Handles imbalanced data well (especially with SMOTE applied).\n",
        "\n",
        "Often achieves better accuracy than other ensemble models."
      ],
      "metadata": {
        "id": "wMGFQ-V2TueY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBClassifier # Import XGBClassifier\n",
        "# Visualizing evaluation Metric Score chart\n",
        "xgb_model = XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "print(\"üéØ Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"üìã Classification Report:\\n\", classification_report(y_test, y_pred_xgb, target_names=le.classes_))\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='d', cmap='YlGnBu',\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(\"XGBoost - Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBClassifier # Import XGBClassifier\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1],\n",
        "    'colsample_bytree': [0.8, 1]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        eval_metric='mlogloss',\n",
        "        random_state=42\n",
        "    ),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "best_xgb = random_search.best_estimator_\n",
        "y_pred_best = best_xgb.predict(X_test)\n",
        "# Accuracy\n",
        "print(\"üéØ Accuracy After Tuning:\", accuracy_score(y_test, y_pred_best)) # Corrected variable name to y_pred_best\n",
        "\n",
        "# Classification Report\n",
        "print(\"üìã Classification Report:\\n\", classification_report(y_test, y_pred_best, target_names=le.classes_)) # Corrected variable name to y_pred_best\n",
        "\n",
        "# Confusion Matrix Plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_best), # Corrected variable name to y_pred_best\n",
        "            annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=le.classes_,\n",
        "            yticklabels=le.classes_)\n",
        "plt.title(\"XGBoost - Confusion Matrix (After Tuning)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technique Used:\n",
        "\n",
        "**RandomizedSearchCV (from sklearn.model_selection)**\n",
        "\n",
        "Why Used:\n",
        "\n",
        "* **RandomizedSearchCV** is an efficient hyperparameter optimization technique that samples a fixed number of parameter settings from the specified hyperparameter distributions.\n",
        "\n",
        "* It is faster than **GridSearchCV** when the hyperparameter space is large.\n",
        "\n",
        "* Helps avoid overfitting and improves generalization by tuning combinations of parameters such as **n_estimators, max_depth, learning_rate, subsample, and colsample_bytree**.\n",
        "\n",
        "* Best suited when we want a good combination of performance and computational efficiency."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After tuning, the model's accuracy improved from **94.6% to 95.4%**, with noticeable gains in F1-score across all tumor classes. This shows better generalization and prediction capability, enhancing the model‚Äôs reliability for real-world use."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High accuracy and F1-score indicate that the model performs well in classifying brain tumors with minimal errors. This can significantly impact medical diagnosis by reducing misclassification, improving early detection, and enabling timely, cost-effective treatment planning."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Used: Support Vector Machine (SVM)**\n",
        "SVM is a powerful supervised learning algorithm used for classification tasks. It works by finding the optimal hyperplane that separates classes with the maximum margin. It is effective in high-dimensional spaces and is robust to overfitting, especially in cases where the number of features exceeds the number of samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "fDn9JiTDYAin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Train the model\n",
        "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"üéØ Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"üìã Classification Report:\\n\", classification_report(y_test, y_pred_svm, target_names=le.classes_))\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='coolwarm',\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(\"SVM - Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [1, 0.1, 0.01],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "grid_svm = GridSearchCV(SVC(probability=True), param_grid, refit=True, cv=5, verbose=2, n_jobs=-1)\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "best_svm_model = grid_svm.best_estimator_\n",
        "y_pred_best_svm = best_svm_model.predict(X_test)\n",
        "\n",
        "print(\"‚úÖ Best Parameters:\", grid_svm.best_params_)\n",
        "print(\"üéØ Accuracy After Tuning:\", accuracy_score(y_test, y_pred_best_svm))\n",
        "print(\"üìã Classification Report:\\n\", classification_report(y_test, y_pred_best_svm, target_names=le.classes_))\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_best_svm), annot=True, fmt='d', cmap='RdPu',\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(\"SVM - Confusion Matrix (After Tuning)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used **GridSearchCV**, a brute-force technique that evaluates all combinations of defined parameters. It‚Äôs ideal for SVM due to the limited number of hyperparameters and provides reliable results via cross-validation."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, after tuning, accuracy improved by ~2.2% (from 93% to 95.2%). The updated evaluation metrics, including precision and F1-score, showed better class balance and reduced misclassifications‚Äîreflected clearly in the post-tuning confusion matrix."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this medical imaging project on brain tumor classification, I used the following evaluation metrics to ensure positive business and clinical impact:\n",
        "\n",
        "* **Accuracy**: To measure the overall performance of the model in predicting the correct tumor class. However, in medical applications, accuracy alone is not enough.\n",
        "\n",
        "* **Precision**: Important to reduce false positives. For example, predicting a tumor when there isn‚Äôt one could lead to unnecessary anxiety and costly follow-up tests.\n",
        "\n",
        "* **Recall (Sensitivity)**: Crucial in the medical domain to reduce false negatives, i.e., missing an actual tumor case. High recall ensures that potential tumors are not overlooked, which can be life-saving.\n",
        "\n",
        "* **F1-Score**: A balance between precision and recall, especially useful for imbalanced datasets. Ensures that the model is not biased toward a single metric.\n",
        "\n",
        "* **Confusion Matrix**: Used for a detailed class-wise breakdown of predictions to understand which tumor classes are misclassified, allowing targeted improvements.\n",
        "\n",
        "These metrics collectively support a model that not only performs well statistically but also provides reliable, ethical, and impactful assistance in real-world diagnostic workflows.\n",
        "\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among the models developed ‚Äî **Random Forest, XGBoost, and SVM** ‚Äî the **XGBoost Classifier** was selected as the final prediction model.\n",
        "\n",
        "Reasons:\n",
        "\n",
        "* It achieved the highest overall performance with an **accuracy of 95.4%** after hyperparameter tuning using **RandomizedSearchCV**.\n",
        "\n",
        "* It handled class imbalances and edge cases more robustly than the other models.\n",
        "\n",
        "* It exhibited **higher F1-scores** across all tumor classes, reducing both false positives and false negatives effectively.\n",
        "\n",
        "* It supports **regularization (L1 & L2)**, which reduced overfitting compared to Random Forest.\n",
        "\n",
        "* Training time was acceptable, and the model scales well for larger datasets, making it suitable for future extensions of this project."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Used:**\n",
        " **XGBoost Classifier** ‚Äî An ensemble learning method based on gradient boosting. It builds decision trees sequentially, where each tree tries to correct the errors of the previous one. XGBoost is highly efficient, accurate, and includes built-in mechanisms to avoid overfitting.\n",
        "\n",
        "**Key Features of XGBoost:**\n",
        "\n",
        "* Uses gradient descent to minimize loss.\n",
        "\n",
        "* Supports missing values inherently.\n",
        "\n",
        "* Includes advanced regularization to control model complexity.\n",
        "\n",
        "* Very effective with imbalanced and structured data.\n",
        "\n",
        "**Model Explainability:**\n",
        "I used **SHAP (SHapley Additive exPlanations)** to interpret the model‚Äôs predictions.\n",
        "\n",
        "* **SHAP Summary Plot**: Shows global feature importance across all predictions.\n",
        "\n",
        "* **SHAP Force Plot**: Demonstrates how each feature contributes to a single prediction.\n",
        "\n",
        "* **Top Features Identified**: Texture, contrast, entropy, and specific statistical values from MRI scans had the most influence in classifying tumor types.\n",
        "\n",
        "These insights help clinicians understand why a model made a specific prediction, increasing trust in AI-assisted diagnostics and supporting medical decision-making."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the best XGBoost model to a file\n",
        "joblib.dump(best_xgb, 'xgboost_brain_tumor_model.joblib')\n",
        "print(\"‚úÖ Model saved as 'xgboost_brain_tumor_model.joblib'\")"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "# Load the saved model\n",
        "loaded_model = joblib.load('xgboost_brain_tumor_model.joblib')\n",
        "\n",
        "# Predict using unseen test data\n",
        "unseen_preds = loaded_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"üîç Classification Report on Unseen Test Data:\")\n",
        "print(classification_report(y_test, unseen_preds))\n"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import joblib\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Title\n",
        "st.set_page_config(page_title=\"Brain Tumor Detector - XGBoost\", layout=\"centered\")\n",
        "st.title(\"üß† Brain Tumor MRI Classification (XGBoost)\")\n",
        "st.markdown(\"Upload a brain MRI image to detect tumor type using an XGBoost model.\")\n",
        "\n",
        "# Load XGBoost model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return joblib.load(\"xgboost_brain_tumor_model.joblib\")\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "# Class names (update these if different)\n",
        "class_names = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
        "\n",
        "# Feature extraction (same as during model training)\n",
        "def preprocess_image(image):\n",
        "    image = image.resize((150, 150))  # or (64, 64) based on your training\n",
        "    image = image.convert('L')  # convert to grayscale if you trained that way\n",
        "    image = np.array(image)\n",
        "    image = image.flatten() / 255.0  # Normalize and flatten\n",
        "    return image.reshape(1, -1)\n",
        "\n",
        "# File uploader\n",
        "uploaded_file = st.file_uploader(\"üì§ Upload an MRI Image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file).convert('RGB')\n",
        "    st.image(image, caption=\"Uploaded Image\", use_container_width=True)\n",
        "\n",
        "    # Preprocess\n",
        "    features = preprocess_image(image)\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(features)\n",
        "    predicted_class = class_names[int(prediction[0])]\n",
        "\n",
        "    st.success(f\"‚úÖ Prediction: **{predicted_class}**\")\n"
      ],
      "metadata": {
        "id": "T_3-oVFxwfmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}